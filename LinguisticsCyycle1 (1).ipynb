{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "MprnumzDYTT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizeText(text):\n",
        "    pattern = r\"\"\"\n",
        "    (?:[A-Za-z]\\.){2,}[A-Z]\n",
        "    | \\w+(?:-\\w+)+\n",
        "    | \\b([A-Za-z]+)(n't|'s|'ll|'em|'ve|'re|'d)\\b\n",
        "    | \\b\\w+\\b\n",
        "    | [.,!?;\"()\\[\\]{}<>]\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    for match in re.finditer(pattern, text, flags=re.VERBOSE):\n",
        "        if match.group(1):\n",
        "            tokens.extend([match.group(1), match.group(2)])\n",
        "        else:\n",
        "            tokens.append(match.group(0))\n",
        "    return tokens\n",
        "\n",
        "text = 'Implement a simple rule-based Text tokenizer for the English language using regular expressions. Your tokenizer should consider punctuations and special symbols as separate tokens. Contractions like \"isn\\'t\" should be regarded as 2 tokens - \"is\" and \"n\\'t\". Also identify abbreviations (eg, U.S.A) and internal hyphenation (eg. ice-cream), as single tokens.'\n",
        "tokens = tokenizeText(text)\n",
        "tokens = set(tokens)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "CJ8SlKBCa5vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145b7666-5bbb-463e-b13e-bfb99974ff9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Implement', 'symbols', 'be', 'Text', '2', 'regular', 'for', 'should', 'tokenizer', 'expressions', 'regarded', 'consider', 'identify', ',', 'simple', 'special', '(', ')', 'tokens', 'language', 'n', 'hyphenation', 'English', 'separate', 'ice-cream', 'internal', 'Also', 'is', 'a', 'punctuations', 'the', 'using', \"n't\", 'single', 'and', 't', 'as', 'like', '.', 'Contractions', 'rule-based', 'eg', 'abbreviations', '\"', 'U.S.A', 'Your'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def isProperPlural(word):\n",
        "    vowels = \"aeiou\"\n",
        "    state = \"start\"\n",
        "    accepts = False\n",
        "    for i in range(1 , 4):\n",
        "      letter = word[-i]\n",
        "      if state == 'start':\n",
        "        if letter == 's':\n",
        "          state = 'plural'\n",
        "        else :\n",
        "          return False\n",
        "      elif state == 'plural':\n",
        "        if letter == 'y':\n",
        "          state = 'end-Y'\n",
        "        else :\n",
        "          return False\n",
        "      elif state == 'end-Y':\n",
        "        if letter in vowels:\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "test = [\"boys\", \"toys\", \"ponies\", \"skies\", \"puppies\", \"boies\", \"toies\", \"ponys\" , \"boykys\"]\n",
        "results = {word: isProperPlural(word) for word in test}\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "vsxDz0DYsSJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67ce0a4-5442-4d55-8786-6504b03894db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'boys': True, 'toys': True, 'ponies': False, 'skies': False, 'puppies': False, 'boies': False, 'toies': False, 'ponys': False, 'boykys': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pluralize(word):\n",
        "    if word.endswith(\"x^s#\") or word.endswith(\"s^s#\") or word.endswith(\"z^s#\"):\n",
        "        return word.replace(\"^s#\", \"es\")\n",
        "    elif word.endswith(\"^s#\"):\n",
        "        return word.replace(\"^s#\", \"s\")\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "test = [\"fox^s#\", \"boy^s#\", \"bus^s#\", \"quiz^s#\", \"dog^s#\"]\n",
        "result = {word: pluralize(word) for word in test}\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iv-pTE8w_6N",
        "outputId": "add8d4ef-e6a1-47d5-a813-4044e533ee4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fox^s#': 'foxes', 'boy^s#': 'boys', 'bus^s#': 'buses', 'quiz^s#': 'quizes', 'dog^s#': 'dogs'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def editDistance(source, target):\n",
        "    sourceLength = len(source)\n",
        "    targetLength = len(target)\n",
        "    operations = []\n",
        "    distanceTable = [[0] * (targetLength + 1) for _ in range(sourceLength + 1)]\n",
        "    for i in range(sourceLength + 1):\n",
        "        distanceTable[i][0] = i\n",
        "    for k in range(targetLength + 1):\n",
        "        distanceTable[0][k] = k\n",
        "    for i in range(1, sourceLength + 1):\n",
        "        for j in range(1, targetLength + 1):\n",
        "            if source[i - 1] == target[j - 1]:\n",
        "                distanceTable[i][j] = distanceTable[i - 1][j - 1]\n",
        "            else:\n",
        "                distanceTable[i][j] = min(\n",
        "                    distanceTable[i][j - 1] + 1,              # Insertion\n",
        "                    distanceTable[i - 1][j] + 1,              # Deletion\n",
        "                    distanceTable[i - 1][j - 1] + 2           # Substitution\n",
        "                )\n",
        "    i, j = sourceLength, targetLength\n",
        "    operations = []\n",
        "    while i > 0 or j > 0:\n",
        "        if i > 0 and j > 0 and source[i - 1] == target[j - 1]:\n",
        "            i, j = i - 1, j - 1\n",
        "        elif i > 0 and distanceTable[i][j] == distanceTable[i - 1][j] + 1:\n",
        "            operations.append(f\"Delete '{source[i - 1]}' from position {i}\")\n",
        "            i -= 1\n",
        "        elif j > 0 and distanceTable[i][j] == distanceTable[i][j - 1] + 1:\n",
        "            operations.append(f\"Insert '{target[j - 1]}' at position {j}\")\n",
        "            j -= 1\n",
        "        else:\n",
        "            operations.append(f\"Substitute '{source[i - 1]}' with '{target[j - 1]}' at position {i}\")\n",
        "            i, j = i - 1, j - 1\n",
        "    operations.reverse()\n",
        "    return distanceTable[sourceLength][targetLength], operations\n",
        "source = \"exclusive\"\n",
        "target = \"invasive\"\n",
        "distance, operands = editDistance(source, target)\n",
        "print(\"Edit Distance:\", distance)\n",
        "print(\"Operations:\")\n",
        "for op in operands:\n",
        "    print(op)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da7hjpjO2J3w",
        "outputId": "173be2d0-acc0-4c7d-f328-c3a0bdb96686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit Distance: 9\n",
            "Operations:\n",
            "Insert 'i' at position 1\n",
            "Insert 'n' at position 2\n",
            "Insert 'v' at position 3\n",
            "Insert 'a' at position 4\n",
            "Delete 'e' from position 1\n",
            "Delete 'x' from position 2\n",
            "Delete 'c' from position 3\n",
            "Delete 'l' from position 4\n",
            "Delete 'u' from position 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "liMmxr-C7qCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}